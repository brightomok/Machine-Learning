preProcValue <- preProcess(train, method = c("center", "scale","pca"))
history()
?history
trainControl(method="glm",PCAthresh = .8)
train
UseMethod
?train
fit2 <- (training$diagnosis~.,data=train,method = "glm",preProcess = c("pca"))
fit2 <- (training$diagnosis~., data=train,method = "glm",preProcess = c("pca"))
fit2 <- (training$diagnosis, data=train,method = "glm",preProcess = c("pca"))
fit2 <- train(training$diagnosis~., data=train,method = "glm",preProcess = c("pca"))
traindex <- training[,c(1, 58:69)]
fit2 <- train(training$diagnosis~., data=traindex,method = "glm",preProcess = c("pca"))
fit2 <- train(diagnosis~., data=traindex,method = "glm",preProcess = c("pca"))
fit2 <- train(diagnosis~., data=traindex,method = "glm",preProcess = c("pca"),thresh=.8)
fit2 <- train(diagnosis~., data=traindex,method = "glm",preProcess = c("pca"))
ctrl <- trainControl(method = "pca", thresh = .8)
ctrl <- trainControl(method = "pca", PCAthresh = .8)
trl <- trainControl(preProcOptions = list(thresh = 0.95))
ctrl <- trainControl(preProcOptions = list(thresh = 0.95))
fit2 <- train(diagnosis~., data=traindex,method = "glm",preProcess = c("pca"), trControl = ctrl)
pred <- predict(fit2,test[,-1])
train <- training[,c(58:69)]
test <- testing[, c(58:69)]
prePred <- predict(preP, train[,-1])
prePred <- predict(fit2, train[,-1])
head(train[,-1])
prePred <- predict(fit2, train)
confusionMatrix(data = prePred, test$diagnosis)
prePred
prePred <- predict(fit2, test)
confusionMatrix(data = prePred, test$diagnosis)
pred <- predict(fit2,test[])
pred <- predict(fit2,test)
confusionMatrix(data = pred, test$diagnosis)
levels(pred)
levels(test$diagnosis)
confusionMatrix(data = pred, testing$diagnosis)
fit <- train(diagnosis~., data = traindex,method="glm")
pred <- predict(fit,test)
confusionMatrix(data = pred, test$diagnosis)
fit <- train(diagnosis~., data = traindex,method="glm")
pred <- predict(fit,test)
confusionMatrix(data = pred, testing$diagnosis)
rm(list=ls())
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
trainIndex = createDataPartition(case, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
segmentationOriginal
head(segmentationOriginal)
split <- split(segmentationOriginal)
split <- split(segmentationOriginal, case)
split <- split(segmentationOriginal, segmentationOriginal$case)
class(segmentationOriginal)
?split
unique(segmentationOriginal$Case)
split <- split(segmentationOriginal, as.Factor(segmentationOriginal$case))
split <- split(segmentationOriginal, factor(segmentationOriginal$case))
split <- split(segmentationOriginal, factor(segmentationOriginal$case))
split <- split(segmentationOriginal, as.Factor(segmentationOriginal$case))
split <- split(segmentationOriginal, segmentationOriginal$case)
segmentationOriginal$Case
split <- split(segmentationOriginal, segmentationOriginal$case)
class(segmentationOriginal$Case)
Train <- segmentationOriginal[segmentationOriginal$Case==train,)
Train <- segmentationOriginal[segmentationOriginal$Case==train,]
Train <- segmentationOriginal[segmentationOriginal$Case== factor(train),]
levels(segmentationOriginal$Case)
Train <- segmentationOriginal[segmentationOriginal$Case== "train",]
head9Train
head(Train)
train
Train
head(segmentationOriginal)
dim(Train)
Trainset <- segmentationOriginal[Case== "train",]
Trainset <- segmentationOriginal["Case" == "train",]
head(Trainset)
Trainset <- segmentationOriginal[which("Case" == train),]
Trainset <- segmentationOriginal[which("Case" == "train"),]
Testset <- segmentationOriginal[which("Case" == "test"),]
head(Trainset)
Testset <- segmentationOriginal[which(segmentationOriginal$Case == test),]
Testset <- segmentationOriginal[which(segmentationOriginal$Case == "test"),]
head(Testset)
Testset <- segmentationOriginal[,which(segmentationOriginal$Case == "test")]
head(Testset)
Testset
which(segmentationOriginal$Case == "test")
levels(segmentationOriginal$Case)
Testset <- segmentationOriginal[which("Case" == "Test"),]
head(Testset)
Testset <- segmentationOriginal[which(,"Case" == "Test")]
Testset <- segmentationOriginal[,which(,"Case" == "Test")]
Testset <- segmentationOriginal[,which("Case" == "Test")]
head(Testset)
Testset <- segmentationOriginal[,which(segmentationOriginal$Case == "Test")]
Testset <- segmentationOriginal[which(segmentationOriginal$Case == "Test"),]
head(Testset)
trainset <- segmentationOriginal[which(segmentationOriginal$Case == "Train"),]
testset <- segmentationOriginal[which(segmentationOriginal$Case == "Test"),]
seed(125)
set.seed(125)
?segmentationOriginal
dim(segmentationOriginal)
modFit <- train(class ~., method ="rpart", data=segmentationOriginal[,-1])
modFit <- train(class ~., method ="rpart", data=segmentationOriginal)
modFit <- train(class ~., method ="rpart", data=trainset)
modFit <- train(Class ~., method ="rpart", data=trainset)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE,main"Classification Tree")
plot(modFit$finalModel, uniform=TRUE,main="Classification Tree")
library(rattle)
install.packages(Rattle)
install.packages("Rattle")
install.packages("rattle")
fancyRpartPlot(modFit$finalModel)
library(rattle)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test <- factor(vowel.test#y)
)
vowel.test <- factor(vowel.test$y)
vowel.train <- factor(vowel.train$y)
boost <- train(y~., method = "gbm",data =vowel.train)
library(caret)
boost <- train(y~., method = "gbm",data =vowel.train)
head(vowel.train)
rm(list=ls())
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test$y <- factor(vowel.test$y)
vowel.train$y <- factor(vowel.train$y)
boost <- train(y~., method = "gbm",data =vowel.train)
train(vowel.train)
head(vowel.train)
rf <- train(y~., method = "rf",data =vowel.train)
boost <- train(y~., method = "rbm",data =vowel.train)
boost <- train(y~., method = "gbm",data =vowel.train)
boost
boost <- train(y~., method = "gbm",data =vowel.train)
boost
rf
set.seed(33833)
boost <- train(y~., method = "gbm",data =vowel.train)
rf <- train(y~., method = "rf",data =vowel.train)
pred_boost <- predict(boost, vowel.test)
pred_rf <- predict(rf, vowel.test)
confusionMatrix(vowel.test,pred_rf)
confusionMatrix(pred_rf, vowel.test)
?confusionMatrix
confusionMatrix(pred_rf, vowel.test$y)
confusionMatrix(pred_rf, vowel.test$y)$overall
confusionMatrix(pred_boost, vowel.test$y)$overall
confusionMatrix(pred_boost, vowel.test$y)$overall[1]
confusionMatrix(pred_boost, vowel.test$y)$overall[1]
match <- (boost == rf)
confusionMatrix(vowel.test$y[match], rf.result[match])$overall[1])
match <- (pred_boost == pred_rf)
confusionMatrix(vowel.test$y[match], rf.result[match])$overall[1])
match <- (pred_boost == pred_rf)
confusionMatrix(vowel.test$y[match], pred_boost[match])$overall[1])
match <- (pred_boost == pred_rf)
confusionMatrix(vowel.test$y[match], pred_boost[match])$overall[1]
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_boost, vowel.test$y)$overall[1]
match <- (pred_boost == pred_rf)
confusionMatrix(vowel.test$y[match], pred_boost[match])$overall[1]
set.seed(62433)
rf <- train(y~., method = "rf",data =vowel.train)
rf <- train(diagnosis~., method = "rf",data =training)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
rf <- train(diagnosis~., method = "rf",data =training)
boost <- train(diagnosis~., method = "gbm",data =training)
lda <- train(diagnosis~., method = "lda",data =training)
confusionMatrix(pred_rf, testing$y)$overall[1]
confusionMatrix(pred_boost, testing$y)$overall[1]
pred_boost <- predict(boost, vowel.test)
pred_boost <- predict(boost, testing)
pred_rf <- predict(rf, testing)
qplot(pred_rf,pred_boost,colour=y, data=training)
qplot(pred_rf,pred_boost,colour=diagnosis, data=training)
qplot(pred_rf,pred_boost,colour=diagnosis, data=testing)
pred_rf <- predict(rf, testing)
pred_lda <- predict(lda, testing)
all_pred <- data.frame(pred_rf,pred_lda,pred_boost, diagnosis = testing$diagnosis)
combinedMod <- train(diagnosis~.,method="rf", data = all_pred)
combinedPred <- predict(combinedMod,all_pred)
confusionMatrix(testing$diagnosis, pred_rf)$overall[1]
confusionMatrix(testing$diagnosis, pred_lda)$overall[1]
confusionMatrix(testing$diagnosis, pred_boost)$overall[1]
final <- predict(combinedMod,testing$diagnosis)
confusionMatrix(testing$diagnosis, final)$overall[1]
library(caret)
library(gbm)
#Training the model
boost <- train(y~., method = "gbm",data =vowel.train)
rf <- train(y~., method = "rf",data =vowel.train)
#Predicting
pred_rf <- predict(rf, vowel.test)
pred_boost <- predict(boost, vowel.test)
#Accuracies
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_boost, vowel.test$y)$overall[1]
#Matched Accuracy
match <- (pred_boost == pred_rf)
confusionMatrix(vowel.test$y[match], pred_boost[match])$overall[1]
qplot(pred_rf,pred_boost,colour=y, data=vowel.train)
qplot(pred_rf,pred_boost,data=vowel.train)
qplot(pred_rf,pred_boost,data=vowel.test)
set.seed(62433)
#Training Random Forest, Boosting, and Linear Discriminant Analysis
rf <- train(y~., method = "rf",data =training)
boost <- train(diagnosis~., method = "gbm",data =training)
lda <- train(diagnosis~., method = "lda",data =training)
#Predicting the Model
pred_rf <- predict(rf, testing)
pred_boost <- predict(boost, testing)
pred_lda <- predict(lda, testing)
#Combining Prediction Sets, training against diagnosis and predicting
all_pred <- data.frame(pred_rf,pred_lda,pred_boost, diagnosis = testing$diagnosis)
combinedMod <- train(diagnosis~.,method="rf", data = all_pred)
combinedPred <- predict(combinedMod,all_pred)
#Accuracies
confusionMatrix(testing$diagnosis, pred_rf)$overall[1]
confusionMatrix(testing$diagnosis, pred_lda)$overall[1]
confusionMatrix(testing$diagnosis, pred_boost)$overall[1]
confusionMatrix(testing$diagnosis, final)$overall[1]
confusionMatrix(testing$diagnosis, pred_rf)$overall[1]
rm(list=ls())
set.seed(62433)
#Training Random Forest, Boosting, and Linear Discriminant Analysis
rf <- train(y~., method = "rf",data =training)
boost <- train(diagnosis~., method = "gbm",data =training)
lda <- train(diagnosis~., method = "lda",data =training)
#Predicting the Model
pred_rf <- predict(rf, testing)
pred_boost <- predict(boost, testing)
pred_lda <- predict(lda, testing)
#Combining Prediction Sets, training against diagnosis and predicting
all_pred <- data.frame(pred_rf,pred_lda,pred_boost, diagnosis = testing$diagnosis)
combinedMod <- train(diagnosis~.,method="rf", data = all_pred)
combinedPred <- predict(combinedMod,all_pred)
#Accuracies
confusionMatrix(testing$diagnosis, pred_rf)$overall[1]
confusionMatrix(testing$diagnosis, pred_lda)$overall[1]
confusionMatrix(testing$diagnosis, pred_boost)$overall[1]
confusionMatrix(testing$diagnosis, combined_pred)$overall[1]
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
#Training Random Forest, Boosting, and Linear Discriminant Analysis
rf <- train(y~., method = "rf",data =training)
boost <- train(diagnosis~., method = "gbm",data =training)
lda <- train(diagnosis~., method = "lda",data =training)
#Predicting the Model
pred_rf <- predict(rf, testing)
pred_boost <- predict(boost, testing)
pred_lda <- predict(lda, testing)
#Combining Prediction Sets, training against diagnosis and predicting
all_pred <- data.frame(pred_rf,pred_lda,pred_boost, diagnosis = testing$diagnosis)
combinedMod <- train(diagnosis~.,method="rf", data = all_pred)
combinedPred <- predict(combinedMod,all_pred)
#Accuracies
confusionMatrix(testing$diagnosis, pred_rf)$overall[1]
confusionMatrix(testing$diagnosis, pred_lda)$overall[1]
confusionMatrix(testing$diagnosis, pred_boost)$overall[1]
confusionMatrix(testing$diagnosis, combined_pred)$overall[1]
set.seed(62433)
#Training Random Forest, Boosting, and Linear Discriminant Analysis
rf <- train(diagnosis~., method = "rf",data =training)
boost <- train(diagnosis~., method = "gbm",data =training)
lda <- train(diagnosis~., method = "lda",data =training)
#Predicting the Model
pred_rf <- predict(rf, testing)
pred_boost <- predict(boost, testing)
pred_lda <- predict(lda, testing)
#Combining Prediction Sets, training against diagnosis and predicting
all_pred <- data.frame(pred_rf,pred_lda,pred_boost, diagnosis = testing$diagnosis)
combinedMod <- train(diagnosis~.,method="rf", data = all_pred)
combinedPred <- predict(combinedMod,all_pred)
#Accuracies
confusionMatrix(testing$diagnosis, pred_rf)$overall[1]
confusionMatrix(testing$diagnosis, pred_lda)$overall[1]
confusionMatrix(testing$diagnosis, pred_boost)$overall[1]
confusionMatrix(testing$diagnosis, combined_pred)$overall[1]
confusionMatrix(testing$diagnosis, combinedPred)$overall[1]
rm(list=ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
lasso <- train(CompressiveStrength~., method = "lasso", data = training)
?plot.enet
lasso
names(lasso)
plot.enet(lasso$finalModel)
?plot.enet
plot.enet(lasso$finalModel)
plot.enet(lasso$finalModel, xvar = "penalty")
library(lubridate) # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
download.file(https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv,dest,file = gaData.csv)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",dest,file = gaData.csv)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv",dest.file = gaData.csv)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv", destfile = gaData.csv)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv", destfile = "gaData.csv")
dat = read.csv("~/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
install.packages("forecast")
library(forecast)
?bats
bats(training)
head(training)
trainning
training
head(training)
bats(training$visitsTumblr)
bats <- bats(training$visitsTumblr)
fcast <- forecast(bast, level = 95, h = dim(testing)[1])
fcast <- forecast(bats, level = 95, h = dim(testing)[1])
fcast
fcast <- forecast(bats, level = 95, h = dim(testing)[1])
bats <- bats(training$visitsTumblr)
bats
fcast$lower
head(fcast)
summary(fcast)
names(fcast)
names(fcast)$model
fcast$model
sum(fcast$lower < testing$visitsTumblr < fcast$upper)
sum(fcast$lower < testing$visitsTumblr &  testing$visitsTumblr < fcast$upper)
sum(fcast$lower < testing$visitsTumblr &  testing$visitsTumblr < fcast$upper)/length(testing)
sum(fcast$lower < testing$visitsTumblr &  testing$visitsTumblr < fcast$upper)/nrow(testing)
rm(list=ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
install.packages("e1071")
install.packages("e1071")
library(e1071)
set.seed(325)
mod_svm <- svm(CompressiveStrength ~ ., data = training)
pred_svm <- predict(mod_svm, testing)
accuracy(pred_svm, testing$CompressiveStrength)
library(caret)
accuracy(pred_svm, testing$CompressiveStrength)
library(forecast)
accuracy(pred_svm, testing$CompressiveStrength)
mod_svm <- svm(CompressiveStrength ~ ., data = training)
pred_svm <- predict(mod_svm, testing)
accuracy(pred_svm, testing$CompressiveStrength)
library(caret)
library(gbm)
#Training the model
boost <- train(y~., method = "gbm",data =vowel.train)
rf <- train(y~., method = "rf",data =vowel.train)
#Predicting
pred_rf <- predict(rf, vowel.test)
pred_boost <- predict(boost, vowel.test)
#Accuracies
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_boost, vowel.test$y)$overall[1]
#Matched Accuracy
match <- (pred_boost == pred_rf)
confusionMatrix(vowel.test$y[match], pred_boost[match])$overall[1]
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
library(caret)
library(gbm)
#Training the model
boost <- train(y~., method = "gbm",data =vowel.train)
rf <- train(y~., method = "rf",data =vowel.train)
#Predicting
pred_rf <- predict(rf, vowel.test)
pred_boost <- predict(boost, vowel.test)
#Accuracies
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_boost, vowel.test$y)$overall[1]
#Matched Accuracy
match <- (pred_boost == pred_rf)
confusionMatrix(vowel.test$y[match], pred_boost[match])$overall[1]
rm(list=ls())
getwd()
setwd("Machine Learning")
setwd("git/Machine Learning")
getwd()
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "training.csv")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "testing.csv")
training <- read.csv("training.csv")
testing <- read.csv("testing.cs")
testing <- read.csv("testing.csv")
setwd("Human Activity Recognition Project")
library(datasets)
data(iris)
mean(iris$Sepal.Length)
head(iris)
apply(iris[, 1:4], 1, mean)
apply(iris[, 1:4], 2, mean)
?apply
with(mtcars, tapply(mpg, cyl, mean))
sapply(mtcars, cyl, mean)
apply(mtcars, 2, mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
with(mtcars, tapply(mpg, cyl, mean))
split(mtcars, mtcars$cyl)
lapply(mtcars, mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
new <- tapply(mtcars$mpg, mtcars$cyl, mean)
tapply(mtcars$hp, mtcars$cyl, mean)
new <- tapply(mtcars$hp, mtcars$cyl, mean)
abs(new[8]-new[4])
abs(new[3]-new[1])
round(abs(new[3]-new[1]))
debug(ls)
ls
ls()
c
q
q
q
Q
mean(iris$Sepal.Length)
undebug(ls)
undebug(ls)
undebug(ls)
undebug(ls)
mean(iris$Sepal.Length)
head(iris)
mean(iris[which("Species" == "virginica")]$Sepal.Length)
mean(iris[which("Species" == "virginica"),]$Sepal.Length)
mean(,iris[which("Species" == "virginica")]$Sepal.Length)
mean(iris[,which("Species" == "virginica")]$Sepal.Length)
mean(iris[which("Species" == "virginica",)]$Sepal.Length)
mean(iris[which("Species" == "virginica"],)$Sepal.Length)
mean(iris[which("Species" == "virginica"),]$Sepal.Length)
mean(iris[,which("Species" == "virginica")]$Sepal.Length)
iris[,which("Species" == "virginica")]
iris[,which(Species == "virginica")]
iris[,which(iris$Species == "virginica")]
iris[which(iris$Species == "virginica"),]
iris[which(iris$Species == "virginica"),]$sepal.length
iris[which(iris$Species == "virginica"),]$Sepal.Length
mean(iris[which(iris$Species == "virginica"),]$Sepal.Length)
round(mean(iris[which(iris$Species == "virginica"),]$Sepal.Length))
set.seed(1)
rpois(5, 2)
?rnorm
rnorm(10, 0, 1)
?qpois
set.seed(10)
x <- rep(0:1, each = 5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
y
plot(y)
?rep
plot(y)
abline(lm(y))
abline(lm(y~x))
?rbinom
```{r 8}
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
```
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
